# 2016/06/09

## 09:33

Ok so, what I need to do is create actual threads and work on the structure
manager.

## 10:48

An idea that I have for the structure manager is that partitioning free space
that is available would cost a bunch of memory. So instead of having an
active partition table, I will have two regions. The region at the start of the
lowest available memory would be the allocation table. This region specifies
basic object information and the regions of memory which are actually used. So
basically there would be a handle table at the start for every allocation. At
the start, the memory would be initialized to contain an intial table of a
given size and a large contigious free chunk. Each allocation chunk would then
have information such as its type, where its pointer is allocated, some GC
information, and basically that would be it. It would have to be small so that
lower memory systems are not insanely pressured into it. There would also need
to be size information also. So right now if a 32-bit field is used for type
and GC flags, then that means two pointer sized fields are used for the
data pointer and the size.

 * 16-bit: 4 + 2 + 2 = 8
 * 32-bit: 4 + 4 + 4 = 12
 * 64-bit: 4 + 8 + 8 = 20

I could actually split the start 32-bit field into other fields which may have
atomic operations performed on it. When it comes to the class type that an
object is, or the length of the array that can be placed in the data pointer
information.

## 11:42

For arrays the type and length could be determined by the table index
information. Then with this, I can have byte arrays which are mapped to
specific regions of memory that are outside of the allocated memory zone.

## 12:07

For simplicity, the memory table contents will only pertain to their own
pool region. This way I can have multiple pools where their table data is not
placed in another pool.

## 12:23

I suppose the given allocation strategy shall be used:

 1. Go through all memory pools
    1. Try to allocate a given amount of bytes.
    2. Check to see if compacting all of the data within a single pool would be
       enough to allocate the given number of bytes (without performing the
       compaction).
       * If there is enough room, then everything in the pool is compacted
         until a large enough area of free space is available.
 2. Try to allocate another memory pool, if it works run the steps for _1_ for
    that given pool.
 3. Garbage collect all memory pools and clear weak/unreferenced objects.
 4. Run step _1_ again.
 5. To the running program, an `OutOfMemoryError` is thrown.

The compaction would have to consider also objects it cannot move (because they
may be locked by a thread).

## 12:34

I suppose for simplicity and some debugging, the identity hash code of an
object will be the table reference index. However a random value would likely
be a better choice. Many of the references would have very close values with
the same higher bits which would make it harder on hash maps. Random would
be the best choice. However, the identity hash code could be a 16-bit value
which is duplicated in the high and low places. This may be enough for Java ME
since there is hopefully not going to be more than 65,000 objects at any one
time.

